# .github/workflows/crawler.yml
name: New Word Crawler Pipeline (Sequential)

on:
  schedule:
    - cron: '0 9 * * *'
  workflow_dispatch:

jobs:
  discover:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      - name: Install dependencies
        run: pip install requests beautifulsoup4 supabase
      - name: Run URL Discoverer (Parallel)
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: python discover_urls.py

  process:
    # discoverジョブの完了を待ってから開始
    needs: discover
    runs-on: ubuntu-latest
    strategy:
      matrix:
        instance: [1] 
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      - name: Install dependencies
        run: |
          pip install sudachipy SudachiDict-full
          pip install requests beautifulsoup4 supabase
      - name: Run Queue Processor (Instance ${{ matrix.instance }})
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: python process_queue.py
