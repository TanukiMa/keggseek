# .github/workflows/crawler.yml
name: New Word Crawler Pipeline (Parallel, Change-Detection)

on:
  schedule:
    - cron: '0 18 * * *' # 毎日午前3時 (JST)
  workflow_dispatch:

jobs:
  discover:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      - name: Install dependencies for discoverer
        run: |
          pip install requests beautifulsoup4 supabase
      - name: Run URL Discoverer and Change Detector
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: python discover_urls.py

  process:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        instance: [1, 2, 3] 
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      - name: Install dependencies for processor
        run: |
          pip install sudachipy SudachiDict-full
          pip install requests beautifulsoup4 supabase
      - name: Run Queue Processor (Instance ${{ matrix.instance }})
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: python process_queue.py
