name: 厚労省サイト専門用語解析 (SudachiDict-full)

on:
  schedule:
    # 毎日午前2時（JST 11時）に実行
    - cron: '0 2 * * *'
  workflow_dispatch:  # 手動実行も可能
    inputs:
      max_workers:
        description: '並列処理数'
        required: false
        default: '1'  # デフォルトを1に削減（LLMタイムアウト対策）
        type: string

env:
  PYTHON_VERSION: '3.11'
  SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
  SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}

jobs:
  analyze-mhlw-terms:
    runs-on: ubuntu-latest
    timeout-minutes: 180  # SudachiDict-fullを考慮して3時間に延長
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install system dependencies (minimal for package installation)
      run: |
        sudo apt-get update
        # パッケージインストール方式のため、build toolsは不要
        echo "ℹ️  システム依存関係は最小限（パッケージインストール方式）"
    
    - name: Install Python dependencies (including SudachiDict-full)
      run: |
        python -m pip install --upgrade pip
        
        echo "📦 Python依存関係インストール中..."
        pip install \
          requests==2.31.0 \
          beautifulsoup4==4.12.2 \
          supabase==2.0.2 \
          sudachipy==0.6.7 \
          huggingface_hub==0.19.4 \
          python-docx==0.8.11 \
          python-pptx==0.6.22 \
          PyPDF2==3.0.1 \
          lxml==4.9.3
        
        echo "📚 Sudachi辞書インストール中..."
        echo "⏰ Full辞書は大容量のため、2-3分かかります..."
        
        # Core辞書も一緒にインストール（互換性のため）
        pip install sudachidict_core
        # Full辞書をメイン辞書として使用
        pip install SudachiDict-full
        
        echo "✅ すべての依存関係インストール完了"
    
name: 厚労省サイト専門用語解析 (辞書ベース判定)

on:
  schedule:
    # 毎日午前2時（JST 11時）に実行
    - cron: '0 2 * * *'
  workflow_dispatch:  # 手動実行も可能
    inputs:
      max_workers:
        description: '並列処理数'
        required: false
        default: '3'  # LLM不使用のため元の値に戻す
        type: string

env:
  PYTHON_VERSION: '3.11'
  SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
  SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}

jobs:
  analyze-mhlw-terms:
    runs-on: ubuntu-latest
    timeout-minutes: 120  # LLM削除で2時間に短縮
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install system dependencies (minimal)
      run: |
        sudo apt-get update
        # LLM不使用のためさらに軽量化
        echo "✅ システム依存関係は最小限（辞書ベース判定）"
    
    - name: Install Python dependencies (SudachiDict-full only)
      run: |
        python -m pip install --upgrade pip
        
        echo "📦 Python依存関係インストール中..."
        pip install \
          requests==2.31.0 \
          beautifulsoup4==4.12.2 \
          supabase==2.0.2 \
          sudachipy==0.6.7 \
          sudachidict_core \
          SudachiDict-full \
          python-docx==0.8.11 \
          python-pptx==0.6.22 \
          PyPDF2==3.0.1 \
          lxml==4.9.3
        
        echo "✅ 依存関係インストール完了（LLM関連なし）"
        
        # インストール確認
        echo "📚 Sudachi辞書確認:"
        pip list | grep -i sudachi
    
    - name: Setup and Test SudachiDict-full (dictionary-based detection)
      run: |
        echo "🔤 SudachiDict-full 設定・動作確認（辞書ベース判定）"
        
        # SudachiPy設定ファイル作成（Full辞書指定）
        mkdir -p ~/.sudachi
        python -c "
        import json
        import os
        from pathlib import Path
        
        # SudachiDict-fullのパスを探す
        try:
            import sudachidict_full
            full_dict_path = Path(sudachidict_full.__file__).parent / 'resources' / 'system.dic'
            print(f'📍 SudachiDict-full パス: {full_dict_path}')
        except ImportError:
            print('⚠️  SudachiDict-fullが見つかりません')
            # フォールバック設定
            full_dict_path = None
        
        # 設定ファイル作成
        config = {
            'systemDict': str(full_dict_path) if full_dict_path and full_dict_path.exists() else None,
            'characterDefinitionFile': 'char.def',
            'inputTextPlugin': [],
            'oovProviderPlugin': [],
            'pathRewritePlugin': [],
            'connectPlugin': []
        }
        
        config_path = Path.home() / '.sudachi' / 'sudachi.json'
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        print(f'📄 設定ファイル作成: {config_path}')
        "
        
        # 動作確認とテスト実行
        python -c "
        import time
        from sudachipy import tokenizer, dictionary
        
        print('🚀 SudachiDict-full 初期化中（辞書ベース判定）...')
        start_time = time.time()
        
        try:
            # 設定ファイルを使用して辞書初期化
            tokenizer_obj = dictionary.Dictionary().create()
            init_time = time.time() - start_time
            print(f'⏱️  初期化完了: {init_time:.2f}秒')
            
            # 辞書ベース新語判定テスト
            test_cases = [
                ('テレメディシン', '既知語か新語かテスト'),
                ('遠隔診療', '既知語か新語かテスト'), 
                ('DX推進', '新語候補'),
                ('医療従事者', '既知語'),
                ('PHRシステム', '新語候補')
            ]
            
            print('\\n📝 辞書ベース新語判定テスト:')
            print('=' * 50)
            
            for word, description in test_cases:
                start = time.time()
                tokens = tokenizer_obj.tokenize(word, tokenizer.Tokenizer.SplitMode.A)
                parse_time = time.time() - start
                
                # 辞書収載判定（簡易版）
                is_single_token = len(tokens) == 1
                token_surface = tokens[0].surface() if tokens else ''
                matches_input = token_surface == word if tokens else False
                
                status = '既知語（辞書収載済み）' if (is_single_token and matches_input) else '新語候補（辞書未収載）'
                
                print(f'  {word}: {status}')
                print(f'    解析結果: {[t.surface() for t in tokens]}')
                print(f'    解析時間: {parse_time*1000:.1f}ms')
                print()
            
            print(f'✅ SudachiDict-full 辞書ベース判定テスト完了')
            print('🎯 LLM不使用で高速・確実な新語検出が可能です')
            
        except Exception as e:
            print(f'❌ SudachiDict-full エラー: {e}')
            raise
        "
    
    - name: Create cache directories
      run: |
        mkdir -p ~/.cache/sudachi
        mkdir -p /tmp
        echo "📁 キャッシュディレクトリ作成完了"
    
    - name: Verify complete environment (without LLM)
      run: |
        echo "🔍 環境確認・動作検証（辞書ベース）"
        echo "================================"
        
        echo "🐍 Python環境:"
        python --version
        
        echo "🔤 SudachiPy + Full辞書 最終確認:"
        python -c "
        from sudachipy import dictionary, tokenizer
        import os
        tokenizer_obj = dictionary.Dictionary().create()
        # 正しいSplitMode列挙型を使用
        tokens = tokenizer_obj.tokenize('厚労省', tokenizer.Tokenizer.SplitMode.A)
        print(f'✅ SudachiDict-full 準備完了 (テスト: {len(tokens)}トークン)')
        "
        
        echo "🗄️ Supabase接続確認:"
        echo "SUPABASE_URL: ${SUPABASE_URL:0:30}..."
        
        echo "📦 インストール状況:"
        # SudachiDict確認
        echo "📚 Sudachi辞書確認:"
        pip list | grep -i sudachi
        
        echo "✅ 環境検証完了 - 辞書ベース判定準備完了"
        echo "💡 LLMは使用せず、SudachiDict-full（170万語）との照合で新語検出"
    
    - name: Initialize Supabase dictionary (service_role key)
      run: |
        echo "🗄️ Supabase 基本辞書初期化（service_role key使用）"
        
        python3 << 'EOF'
        import os
        from supabase import create_client
        
        print("📡 Supabase接続中（service_role key使用）...")
        
        # service_role keyで接続（RLS無視）
        client = create_client(
            os.environ['SUPABASE_URL'], 
            os.environ['SUPABASE_KEY']
        )
        
        # 基本辞書データ
        basic_words = [
            {'word': '医療', 'reading': 'イリョウ', 'part_of_speech': '名詞', 'source': 'basic'},
            {'word': '厚生労働省', 'reading': 'コウセイロウドウショウ', 'part_of_speech': '名詞', 'source': 'basic'},
            {'word': '健康', 'reading': 'ケンコウ', 'part_of_speech': '名詞', 'source': 'basic'},
            {'word': '診療', 'reading': 'シンリョウ', 'part_of_speech': '名詞', 'source': 'basic'},
            {'word': '薬事', 'reading': 'ヤクジ', 'part_of_speech': '名詞', 'source': 'basic'},
            {'word': '保険', 'reading': 'ホケン', 'part_of_speech': '名詞', 'source': 'basic'},
            {'word': '介護', 'reading': 'カイゴ', 'part_of_speech': '名詞', 'source': 'basic'},
            {'word': '福祉', 'reading': 'フクシ', 'part_of_speech': '名詞', 'source': 'basic'}
        ]
        
        try:
            # 既存データ確認
            existing_count = client.table('dictionary_words').select('id', count='exact').execute()
            print(f"📊 既存辞書語彙数: {existing_count.count}語")
            
            if existing_count.count == 0:
                print("📝 基本辞書初期化中...")
                result = client.table('dictionary_words').insert(basic_words).execute()
                print(f"✅ 基本辞書を初期化しました ({len(result.data)}語)")
            else:
                print("ℹ️  辞書は既に初期化済みです")
            
            # 最終統計
            final_count = client.table('dictionary_words').select('id', count='exact').execute()
            print(f"📚 現在の辞書語彙数: {final_count.count}語")
            
        except Exception as e:
            print(f"❌ Supabase操作エラー: {e}")
            # service_role keyなら権限問題は発生しないはず
            raise e
            
        print("✅ Supabase辞書初期化完了")
        EOF
    
    - name: Run MHLW crawler (dictionary-based detection)
      env:
        MAX_WORKERS: ${{ github.event.inputs.max_workers || '3' }}
      run: |
        echo "🚀 厚労省サイト解析クローラー実行開始"
        echo "====================================="
        echo "設定:"
        echo "  - 並列処理数: $MAX_WORKERS"
        echo "  - 辞書: SudachiDict-full (170万語)"
        echo "  - 新語判定: 辞書ベース（LLM不使用）"
        echo "  - 対象: 厚労省サイト（HTML, PDF, DOCX, PPTX）"
        echo ""
        
        # Pythonパス確認
        echo "🐍 Python環境確認:"
        python --version
        which python
        echo "PYTHONPATH: ${PYTHONPATH:-未設定}"
        
        # 必要なファイルの存在確認
        echo "📁 ファイル確認:"
        if [ -f "main_crawler.py" ]; then
            echo "✅ main_crawler.py 存在"
            echo "📄 ファイルサイズ: $(wc -c < main_crawler.py) bytes"
            echo "📄 先頭5行:"
            head -5 main_crawler.py
        else
            echo "❌ main_crawler.py が見つかりません"
            echo "📂 現在のディレクトリ内容:"
            ls -la
            echo "❌ クローラー実行を停止します"
            exit 1
        fi
        
        echo ""
        echo "🎯 クローラー実行開始..."
        echo "======================"
        
        python3 << 'EOF'
        import sys
        import os
        import traceback
        from datetime import datetime
        import importlib.util
        
        print(f"🕒 実行開始時刻: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"🔧 Python版: {sys.version}")
        print(f"📂 作業ディレクトリ: {os.getcwd()}")
        print(f"🛣️  Python Path: {sys.path[:3]}...")
        
        # main_crawler.pyの存在確認
        crawler_path = os.path.join(os.getcwd(), 'main_crawler.py')
        if not os.path.exists(crawler_path):
            print(f"❌ {crawler_path} が存在しません")
            print("📂 ディレクトリ内容:")
            for item in os.listdir('.'):
                print(f"  - {item}")
            sys.exit(1)
        
        # モジュールのインポート確認
        try:
            print("📦 依存関係インポートテスト...")
            
            # 主要ライブラリのインポート確認
            import requests
            print(f"  ✅ requests: {requests.__version__}")
            
            from sudachipy import tokenizer, dictionary
            print("  ✅ sudachipy: インポート成功")
            
            from supabase import create_client
            print("  ✅ supabase: インポート成功")
            
            print("📦 全ての依存関係が利用可能です")
            
        except ImportError as e:
            print(f"❌ 依存関係インポートエラー: {e}")
            sys.exit(1)
        
        # メインクローラーのインポートと実行
        try:
            print("🔄 main_crawler モジュールのインポート中...")
            
            # sys.pathに現在のディレクトリを追加
            if os.getcwd() not in sys.path:
                sys.path.insert(0, os.getcwd())
            
            # インポート実行
            from main_crawler import MhlwCrawler
            print("✅ MhlwCrawler クラスのインポート成功")
            
            # クローラーインスタンス作成
            print("🔧 クローラーインスタンス作成中...")
            crawler = MhlwCrawler()
            print("✅ クローラーインスタンス作成成功（辞書ベース判定）")
            
            # 実行パラメータ
            max_workers = int(os.environ.get('MAX_WORKERS', '3'))
            print(f"👥 並列処理数: {max_workers}")
            
            # *** メイン実行 ***
            print("🚀 クローリング・解析開始...")
            print("-" * 40)
            
            crawler.run(max_workers=max_workers)
            
            print("-" * 40)
            print(f"🕒 実行完了時刻: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print("✅ 厚労省サイト解析完了（辞書ベース新語検出）")
            
        except Exception as e:
            print(f"❌ クローラー実行エラー: {e}")
            print("🔍 詳細なエラー情報:")
            traceback.print_exc()
            
            # エラー診断
            error_str = str(e)
            if "ModuleNotFoundError" in error_str:
                print("💡 モジュール不足の可能性があります")
            elif "Permission" in error_str:
                print("💡 権限問題の可能性があります")
            elif "Connection" in error_str:
                print("💡 ネットワーク接続問題の可能性があります")
            
            sys.exit(1)
        EOF
        
        echo ""
        echo "🎉 クローラー実行ステップ完了"
    
    - name: Generate detailed analysis report (dictionary-based)
      if: always()
      run: |
        echo "📊 解析結果レポート生成中（辞書ベース判定）..."
        
        python3 << 'EOF'
        import os
        from supabase import create_client
        from datetime import datetime, timedelta
        
        client = create_client(os.environ['SUPABASE_URL'], os.environ['SUPABASE_KEY'])
        
        # 今日の結果サマリー
        today = datetime.now().date()
        
        print("📈 厚労省サイト専門用語解析結果")
        print("=" * 50)
        print(f"🕒 実行日時: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"🔤 使用辞書: SudachiDict-full (170万語)")
        print(f"🧠 判定方式: 辞書ベース（LLM不使用）")
        print("")
        
        # 新語候補数
        try:
            new_words = client.table('new_word_candidates')\
                .select('*')\
                .gte('created_at', today.isoformat())\
                .execute()
            
            # 処理URL数
            processed = client.table('processed_urls')\
                .select('*')\
                .gte('created_at', today.isoformat())\
                .execute()
            
            # 抽出された全単語数
            extracted = client.table('extracted_words')\
                .select('*')\
                .gte('first_found', today.isoformat())\
                .execute()
            
            print(f"📄 処理済URL: {len(processed.data)}件")
            print(f"🔤 抽出単語: {len(extracted.data)}語")
            print(f"🆕 新語候補: {len(new_words.data)}語")
            
            if new_words.data:
                print(f"📊 新語発見率: {len(new_words.data)/max(len(extracted.data),1)*100:.1f}%")
                
                print("\\n🔍 発見された新語候補 TOP 15:")
                print("-" * 50)
                
                # 信頼度でソート
                sorted_words = sorted(new_words.data, 
                                    key=lambda x: x.get('confidence_score', 0), 
                                    reverse=True)
                
                for i, word in enumerate(sorted_words[:15], 1):
                    word_text = word.get('word', 'N/A')
                    reading = word.get('reading', '不明')
                    confidence = word.get('confidence_score', 0)
                    pos = word.get('part_of_speech', '不明')
                    reasoning = word.get('llm_reasoning', '判定理由不明')[:60]
                    
                    print(f"{i:2d}. {word_text} ({reading})")
                    print(f"    品詞: {pos} | 信頼度: {confidence:.3f}")
                    print(f"    判定: {reasoning}...")
                    print()
            else:
                print("ℹ️  今回の実行では新語候補は見つかりませんでした")
            
            # 辞書統計
            total_dict = client.table('dictionary_words').select('id', count='exact').execute()
            print(f"📚 Supabase基本辞書語彙数: {total_dict.count:,}語")
            print(f"📖 SudachiDict-full: 約170万語")
            print(f"🎯 新語判定: 両辞書に未収載の名詞（3文字以上）")
            
        except Exception as e:
            print(f"⚠️  レポート生成エラー: {e}")
            import traceback
            traceback.print_exc()
        
        print("\\n✅ 解析完了")
        print("🎯 SudachiDict-fullによる辞書ベース高速新語検出が完了しました")
        print("⚡ LLM不使用により、タイムアウト無し・高速処理を実現")
        EOF
    
    - name: Cleanup and optimize storage
      if: always()
      run: |
        echo "🧹 クリーンアップ実行中..."
        
        # 一時ファイル削除
        rm -rf /tmp/*.pdf /tmp/*.docx /tmp/*.pptx /tmp/*.txt
        
        # pip キャッシュクリア（容量節約）
        pip cache purge
        
        # ディスク使用量確認
        echo "💽 ディスク使用量:"
        df -h | head -2
        
        echo "✅ クリーンアップ完了"
    
    - name: Upload comprehensive logs
      if: failure()
      uses: actions/upload-artifact@v4
      with:
        name: mhlw-crawler-logs-${{ github.run_id }}
        path: |
          *.log
          /tmp/crawler_*.txt
          /tmp/sudachi_*.log
          /var/log/syslog
        retention-days: 14
        if-no-files-found: ignore
    
    - name: Setup and Test SudachiDict-full
      run: |
        echo "🔤 SudachiDict-full 設定・動作確認・テスト実行"
        
        # SudachiPy設定ファイル作成（Full辞書指定）
        mkdir -p ~/.sudachi
        python -c "
        import json
        import os
        from pathlib import Path
        
        # SudachiDict-fullのパスを探す
        try:
            import sudachidict_full
            full_dict_path = Path(sudachidict_full.__file__).parent / 'resources' / 'system.dic'
            print(f'📍 SudachiDict-full パス: {full_dict_path}')
        except ImportError:
            print('⚠️  SudachiDict-fullが見つかりません')
            # フォールバック設定
            full_dict_path = None
        
        # 設定ファイル作成
        config = {
            'systemDict': str(full_dict_path) if full_dict_path and full_dict_path.exists() else None,
            'characterDefinitionFile': 'char.def',
            'inputTextPlugin': [],
            'oovProviderPlugin': [],
            'pathRewritePlugin': [],
            'connectPlugin': []
        }
        
        config_path = Path.home() / '.sudachi' / 'sudachi.json'
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        print(f'📄 設定ファイル作成: {config_path}')
        "
        
        # 動作確認とテスト実行
        python -c "
        import time
        from sudachipy import tokenizer, dictionary
        
        print('🚀 SudachiDict-full 初期化中...')
        start_time = time.time()
        
        try:
            # 設定ファイルを使用して辞書初期化
            tokenizer_obj = dictionary.Dictionary().create()
            init_time = time.time() - start_time
            print(f'⏱️  初期化完了: {init_time:.2f}秒')
            
            # 厚労省・医療関連の専門用語でテスト
            test_cases = [
                '厚生労働省の新しい施策について',
                'テレメディシンによる遠隔診療',
                'レセプト電算処理システム',
                '診療報酬点数表の改定',
                '医療DX推進本部',
                'PHR（Personal Health Record）',
                '地域包括ケアシステム',
                '薬事・食品衛生審議会'
            ]
            
            print('\\n📝 専門用語解析テスト結果:')
            print('=' * 50)
            
            total_tokens = 0
            for i, text in enumerate(test_cases, 1):
                start = time.time()
                tokens = tokenizer_obj.tokenize(text, tokenizer.Tokenizer.SplitMode.A)
                parse_time = time.time() - start
                total_tokens += len(tokens)
                
                print(f'\\n{i}. 「{text}」')
                print(f'   解析時間: {parse_time*1000:.1f}ms | トークン数: {len(tokens)}')
                print('   形態素解析結果:')
                
                for token in tokens:
                    surface = token.surface()
                    reading = token.reading_form() or 'ーー'
                    pos = token.part_of_speech()[0]
                    
                    # 専門用語らしいものをハイライト
                    if pos == '名詞' and len(surface) >= 3:
                        print(f'   🔍 {surface} ({reading}) [{pos}] ← 専門用語候補')
                    else:
                        print(f'     {surface} ({reading}) [{pos}]')
            
            print(f'\\n✅ SudachiDict-full テスト完了')
            print(f'📊 総解析: {len(test_cases)}文 / {total_tokens}トークン')
            print('🎯 専門用語の詳細な分割・読み取りが確認できました')
            
        except Exception as e:
            print(f'❌ SudachiDict-full 初期化エラー: {e}')
            print('🔄 フォールバック: デフォルト辞書を使用します')
            
            # フォールバック処理
            tokenizer_obj = dictionary.Dictionary().create()
            tokens = tokenizer_obj.tokenize('厚生労働省', tokenizer.Tokenizer.SplitMode.A)
            print(f'✅ デフォルト辞書で動作確認完了 ({len(tokens)}トークン)')
        "
        
        echo "📚 インストール済み辞書確認:"
        pip list | grep -i sudachi
    
    - name: Create cache directories
      run: |
        mkdir -p ~/.cache/sudachi
        mkdir -p /tmp
        echo "📁 キャッシュディレクトリ作成完了"
    
    - name: Verify complete environment
      run: |
        echo "🔍 環境確認・動作検証"
        echo "=========================="
        
        echo "🐍 Python環境:"
        python --version
        
        echo "🤖 llama-cli確認:"
        if command -v llama-cli >/dev/null 2>&1; then
            echo "✅ llama-cli found in PATH"
            llama-cli --version 2>/dev/null || llama-cli --help | head -3
        elif [ -f "/usr/local/bin/llama-cli" ]; then
            echo "✅ llama-cli found at /usr/local/bin/llama-cli (source build)"
            /usr/local/bin/llama-cli --version 2>/dev/null || /usr/local/bin/llama-cli --help | head -3
        else
            echo "❌ llama-cli not found"
            exit 1
        fi
        
        echo "🔤 SudachiPy + Full辞書 最終確認:"
        python -c "
        from sudachipy import dictionary, tokenizer
        import os
        tokenizer_obj = dictionary.Dictionary().create()
        # 正しいSplitMode列挙型を使用
        tokens = tokenizer_obj.tokenize('厚労省', tokenizer.Tokenizer.SplitMode.A)
        print(f'✅ SudachiDict-full 準備完了 (テスト: {len(tokens)}トークン)')
        "
        
        echo "🗄️ Supabase接続確認:"
        echo "SUPABASE_URL: ${SUPABASE_URL:0:30}..."
        
        echo "🤖 LLMモデル確認:"
        echo "Model path: $LLAMA_MODEL_PATH"
        echo "CLI path: $LLAMA_CLI_PATH"
        if [ -f "$LLAMA_MODEL_PATH" ]; then
            file "$LLAMA_MODEL_PATH"
        else
            echo "❌ Model file not found: $LLAMA_MODEL_PATH"
        fi
        
        echo "📦 インストール状況:"
        # パッケージ版の確認
        if dpkg -l | grep -q llama; then
            echo "✅ llama.cpp package installed:"
            dpkg -l | grep llama
        else
            echo "ℹ️  llama.cpp installed via source build"
        fi
        
        # SudachiDict確認
        echo "📚 Sudachi辞書確認:"
        pip list | grep -i sudachi
        
        echo "✅ 環境検証完了 - すべて正常"
    
    - name: Initialize Supabase dictionary (basic words)
      run: |
        echo "🗄️ Supabase 基本辞書初期化"
        
        python3 << 'EOF'
        import os
        from supabase import create_client
        
        print("📡 Supabase接続中...")
        
        # 環境変数確認
        supabase_url = os.environ.get('SUPABASE_URL')
        supabase_key = os.environ.get('SUPABASE_KEY')
        
        if not supabase_url or not supabase_key:
            print("❌ Supabase認証情報が不足しています")
            exit(1)
        
        print(f"🔑 使用中のキー: {'service_role' if len(supabase_key) > 100 else 'anon'}タイプ")
        
        try:
            client = create_client(supabase_url, supabase_key)
            
            # 接続テスト（読み取り）
            print("📖 接続テスト中...")
            test_read = client.table('dictionary_words').select('id').limit(1).execute()
            print(f"✅ 読み取り成功: {len(test_read.data)}件")
            
            # 厚労省・医療分野の基本辞書語彙
            basic_words = [
                {'word': '医療', 'reading': 'イリョウ', 'part_of_speech': '名詞', 'source': 'basic'},
                {'word': '厚生労働省', 'reading': 'コウセイロウドウショウ', 'part_of_speech': '名詞', 'source': 'basic'},
                {'word': '健康', 'reading': 'ケンコウ', 'part_of_speech': '名詞', 'source': 'basic'},
                {'word': '診療', 'reading': 'シンリョウ', 'part_of_speech': '名詞', 'source': 'basic'},
                {'word': '薬事', 'reading': 'ヤクジ', 'part_of_speech': '名詞', 'source': 'basic'},
                {'word': '保険', 'reading': 'ホケン', 'part_of_speech': '名詞', 'source': 'basic'},
                {'word': '介護', 'reading': 'カイゴ', 'part_of_speech': '名詞', 'source': 'basic'},
                {'word': '福祉', 'reading': 'フクシ', 'part_of_speech': '名詞', 'source': 'basic'}
            ]
            
            # 既存データ確認
            existing_count = client.table('dictionary_words').select('id', count='exact').execute()
            print(f"📊 既存辞書語彙数: {existing_count.count}語")
            
            if existing_count.count == 0:
                print("📝 基本辞書初期化中...")
                
                # RLSエラー対策：一つずつ挿入してエラーハンドリング
                successful_inserts = 0
                for word_data in basic_words:
                    try:
                        result = client.table('dictionary_words').insert(word_data).execute()
                        if result.data:
                            successful_inserts += 1
                    except Exception as word_error:
                        print(f"⚠️  単語挿入失敗 '{word_data['word']}': {word_error}")
                
                if successful_inserts > 0:
                    print(f"✅ 基本辞書を部分的に初期化しました ({successful_inserts}/{len(basic_words)}語)")
                else:
                    print("⚠️  基本辞書の初期化に失敗しました（RLSポリシー問題の可能性）")
                    print("💡 ヒント: service_roleキーを使用することを推奨します")
            else:
                print("ℹ️  辞書は既に初期化済みです")
            
            # 最終統計
            final_count = client.table('dictionary_words').select('id', count='exact').execute()
            print(f"📚 現在の辞書語彙数: {final_count.count}語")
            
        except Exception as e:
            error_msg = str(e)
            print(f"❌ Supabase操作エラー: {error_msg}")
            
            # RLSエラーの診断
            if "row-level security policy" in error_msg:
                print("🔒 RLS (Row Level Security) ポリシーエラーが検出されました")
                print("🔧 解決方法:")
                print("  1. GitHub SecretsでSUPABASE_KEYをservice_roleキーに変更")
                print("  2. または Supabaseで適切なRLSポリシーを設定")
                print("  3. 詳細: https://supabase.com/docs/guides/auth/row-level-security")
            
            # エラーでも処理継続（辞書なしでも動作可能）
            print("⚠️  辞書初期化をスキップして処理を継続します")
            
        print("✅ Supabase辞書初期化ステップ完了")
        EOF
    
    - name: Run MHLW crawler (with enhanced debugging)
      env:
        MAX_WORKERS: ${{ github.event.inputs.max_workers || '1' }}  # デフォルト1に削減
      run: |
        echo "🚀 厚労省サイト解析クローラー実行開始"
        echo "====================================="
        echo "設定:"
        echo "  - 並列処理数: $MAX_WORKERS（LLMタイムアウト対策で削減）"
        echo "  - 辞書: SudachiDict-full (170万語)"
        echo "  - 対象: 厚労省サイト（HTML, PDF, DOCX, PPTX）"
        echo "  - LLMモデル: $LLAMA_MODEL_PATH"
        echo "  - Supabase: ${SUPABASE_URL:0:30}..."
        echo ""
        
        # Pythonパス確認
        echo "🐍 Python環境確認:"
        python --version
        which python
        echo "PYTHONPATH: ${PYTHONPATH:-未設定}"
        
        # 必要なファイルの存在確認
        echo "📁 ファイル確認:"
        if [ -f "main_crawler.py" ]; then
            echo "✅ main_crawler.py 存在"
            echo "📄 ファイルサイズ: $(wc -c < main_crawler.py) bytes"
            echo "📄 先頭5行:"
            head -5 main_crawler.py
        else
            echo "❌ main_crawler.py が見つかりません"
            echo "📂 現在のディレクトリ内容:"
            ls -la
            echo "❌ クローラー実行を停止します"
            exit 1
        fi
        
        echo ""
        echo "🎯 クローラー実行開始..."
        echo "======================"
        
        python3 << 'EOF'
        import sys
        import os
        import traceback
        from datetime import datetime
        import importlib.util
        
        print(f"🕒 実行開始時刻: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"🔧 Python版: {sys.version}")
        print(f"📂 作業ディレクトリ: {os.getcwd()}")
        print(f"🛣️  Python Path: {sys.path[:3]}...")
        
        # main_crawler.pyの存在確認
        crawler_path = os.path.join(os.getcwd(), 'main_crawler.py')
        if not os.path.exists(crawler_path):
            print(f"❌ {crawler_path} が存在しません")
            print("📂 ディレクトリ内容:")
            for item in os.listdir('.'):
                print(f"  - {item}")
            sys.exit(1)
        
        # モジュールのインポート確認
        try:
            print("📦 依存関係インポートテスト...")
            
            # 主要ライブラリのインポート確認
            import requests
            print(f"  ✅ requests: {requests.__version__}")
            
            from sudachipy import tokenizer, dictionary
            print("  ✅ sudachipy: インポート成功")
            
            from supabase import create_client
            print("  ✅ supabase: インポート成功")
            
            print("📦 全ての依存関係が利用可能です")
            
        except ImportError as e:
            print(f"❌ 依存関係インポートエラー: {e}")
            sys.exit(1)
        
        # メインクローラーのインポートと実行
        try:
            print("🔄 main_crawler モジュールのインポート中...")
            
            # sys.pathに現在のディレクトリを追加
            if os.getcwd() not in sys.path:
                sys.path.insert(0, os.getcwd())
            
            # インポート実行
            from main_crawler import MhlwCrawler
            print("✅ MhlwCrawler クラスのインポート成功")
            
            # クローラーインスタンス作成
            print("🔧 クローラーインスタンス作成中...")
            crawler = MhlwCrawler()
            print("✅ クローラーインスタンス作成成功")
            
            # 実行パラメータ
            max_workers = int(os.environ.get('MAX_WORKERS', '3'))
            print(f"👥 並列処理数: {max_workers}")
            
            # *** メイン実行 ***
            print("🚀 クローリング・解析開始...")
            print("-" * 40)
            
            crawler.run(max_workers=max_workers)
            
            print("-" * 40)
            print(f"🕒 実行完了時刻: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print("✅ 厚労省サイト解析完了")
            
        except Exception as e:
            print(f"❌ クローラー実行エラー: {e}")
            print("🔍 詳細なエラー情報:")
            traceback.print_exc()
            
            # エラー診断
            error_str = str(e)
            if "ModuleNotFoundError" in error_str:
                print("💡 モジュール不足の可能性があります")
            elif "Permission" in error_str:
                print("💡 権限問題の可能性があります")
            elif "Connection" in error_str:
                print("💡 ネットワーク接続問題の可能性があります")
            
            sys.exit(1)
        EOF
        
        echo ""
        echo "🎉 クローラー実行ステップ完了"
    
    - name: Generate detailed analysis report
      if: always()
      run: |
        echo "📊 解析結果レポート生成中..."
        
        python3 << 'EOF'
        import os
        from supabase import create_client
        from datetime import datetime, timedelta
        
        client = create_client(os.environ['SUPABASE_URL'], os.environ['SUPABASE_KEY'])
        
        # 今日の結果サマリー
        today = datetime.now().date()
        
        print("📈 厚労省サイト専門用語解析結果")
        print("=" * 50)
        print(f"🕒 実行日時: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"🔤 使用辞書: SudachiDict-full (170万語)")
        print("")
        
        # 新語候補数
        try:
            new_words = client.table('new_word_candidates')\
                .select('*')\
                .gte('created_at', today.isoformat())\
                .execute()
            
            # 処理URL数
            processed = client.table('processed_urls')\
                .select('*')\
                .gte('created_at', today.isoformat())\
                .execute()
            
            # 抽出された全単語数
            extracted = client.table('extracted_words')\
                .select('*')\
                .gte('first_found', today.isoformat())\
                .execute()
            
            print(f"📄 処理済URL: {len(processed.data)}件")
            print(f"🔤 抽出単語: {len(extracted.data)}語")
            print(f"🆕 新語候補: {len(new_words.data)}語")
            
            if new_words.data:
                print(f"📊 新語発見率: {len(new_words.data)/max(len(extracted.data),1)*100:.1f}%")
                
                print("\\n🔍 発見された新語候補 TOP 10:")
                print("-" * 40)
                
                # 信頼度でソート
                sorted_words = sorted(new_words.data, 
                                    key=lambda x: x.get('confidence_score', 0), 
                                    reverse=True)
                
                for i, word in enumerate(sorted_words[:10], 1):
                    word_text = word.get('word', 'N/A')
                    reading = word.get('reading', '不明')
                    confidence = word.get('confidence_score', 0)
                    pos = word.get('part_of_speech', '不明')
                    reasoning = word.get('llm_reasoning', '理由不明')[:50]
                    
                    print(f"{i:2d}. {word_text} ({reading})")
                    print(f"    品詞: {pos} | 信頼度: {confidence:.3f}")
                    print(f"    理由: {reasoning}...")
                    print()
            else:
                print("ℹ️  今回の実行では新語候補は見つかりませんでした")
            
            # 辞書統計
            total_dict = client.table('dictionary_words').select('id', count='exact').execute()
            print(f"📚 現在の辞書語彙数: {total_dict.count:,}語")
            
        except Exception as e:
            print(f"⚠️  レポート生成エラー: {e}")
            import traceback
            traceback.print_exc()
        
        print("\\n✅ 解析完了")
        print("🎯 SudachiDict-fullによる高精度専門用語解析が完了しました")
        EOF
    
    - name: Cleanup and optimize storage
      if: always()
      run: |
        echo "🧹 クリーンアップ実行中..."
        
        # 一時ファイル削除
        rm -rf /tmp/*.pdf /tmp/*.docx /tmp/*.pptx /tmp/*.txt
        
        # pip キャッシュクリア（容量節約）
        pip cache purge
        
        # modelsディレクトリは保持（次回実行時の再ダウンロード回避）
        echo "💾 LLMモデルファイルは保持（再利用のため）"
        
        # ディスク使用量確認
        echo "💽 ディスク使用量:"
        df -h | head -2
        
        echo "✅ クリーンアップ完了"
    
    - name: Upload comprehensive logs
      if: failure()
      uses: actions/upload-artifact@v4
      with:
        name: mhlw-crawler-logs-${{ github.run_id }}
        path: |
          *.log
          /tmp/crawler_*.txt
          /tmp/sudachi_*.log
          /var/log/syslog
        retention-days: 14
        if-no-files-found: ignore
