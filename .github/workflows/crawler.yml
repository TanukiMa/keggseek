name: 厚労省サイト専門用語解析 (SudachiDict-full)

on:
  schedule:
    # 毎日午前2時（JST 11時）に実行
    - cron: '0 2 * * *'
  workflow_dispatch:  # 手動実行も可能
    inputs:
      max_workers:
        description: '並列処理数'
        required: false
        default: '3'
        type: string

env:
  PYTHON_VERSION: '3.11'
  SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
  SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}

jobs:
  analyze-mhlw-terms:
    runs-on: ubuntu-latest
    timeout-minutes: 180  # SudachiDict-fullを考慮して3時間に延長
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install system dependencies (minimal for package installation)
      run: |
        sudo apt-get update
        # パッケージインストール方式のため、build toolsは不要
        echo "ℹ️  システム依存関係は最小限（パッケージインストール方式）"
    
    - name: Install Python dependencies (including SudachiDict-full)
      run: |
        python -m pip install --upgrade pip
        
        echo "📦 Python依存関係インストール中..."
        pip install \
          requests==2.31.0 \
          beautifulsoup4==4.12.2 \
          supabase==2.0.2 \
          sudachipy==0.6.7 \
          huggingface_hub==0.19.4 \
          python-docx==0.8.11 \
          python-pptx==0.6.22 \
          PyPDF2==3.0.1 \
          lxml==4.9.3
        
        echo "📚 Sudachi辞書インストール中..."
        echo "⏰ Full辞書は大容量のため、2-3分かかります..."
        
        # Core辞書も一緒にインストール（互換性のため）
        pip install sudachidict_core
        # Full辞書をメイン辞書として使用
        pip install SudachiDict-full
        
        echo "✅ すべての依存関係インストール完了"
    
    - name: Install llama.cpp from Debian sid (with GPG fix)
      run: |
        echo "🔧 llama.cpp インストール中（Debian sid リポジトリから）"
        
        # Debian GPGキーを追加（署名検証のため）
        echo "🔑 Debian GPGキー追加中..."
        sudo apt-get install -y gnupg
        
        # Debian公式GPGキーを追加
        wget -qO- https://ftp-master.debian.org/keys/archive-key-12.asc | sudo gpg --dearmor -o /etc/apt/trusted.gpg.d/debian-archive-keyring.gpg
        wget -qO- https://ftp-master.debian.org/keys/archive-key-12-security.asc | sudo gpg --dearmor -o /etc/apt/trusted.gpg.d/debian-archive-keyring-security.gpg
        
        # sidリポジトリ追加
        echo "📦 Debian sidリポジトリ追加中..."
        echo "deb http://deb.debian.org/debian sid main" | sudo tee /etc/apt/sources.list.d/sid.list
        
        # 優先度設定（sidからは必要なパッケージのみ）
        sudo tee /etc/apt/preferences.d/llama-cpp-pin << 'EOF'
        Package: llama.cpp
        Pin: release a=sid
        Pin-Priority: 500

        Package: *
        Pin: release a=sid
        Pin-Priority: 100
        EOF
        
        # パッケージリスト更新
        echo "🔄 パッケージリスト更新中..."
        if ! sudo apt update; then
            echo "⚠️  GPG署名エラーが継続する場合、ソースビルドにフォールバック"
            
            # フォールバック: ソースビルド
            echo "🛠️  llama.cpp ソースビルドを実行中..."
            sudo apt-get install -y build-essential cmake
            
            git clone --depth 1 https://github.com/ggerganov/llama.cpp.git /tmp/llama.cpp
            cd /tmp/llama.cpp
            make -j$(nproc) LLAMA_NO_ACCELERATE=1
            sudo cp main /usr/local/bin/llama-cli
            sudo cp server /usr/local/bin/llama-server
            echo "LLAMA_CLI_PATH=/usr/local/bin/llama-cli" >> $GITHUB_ENV
            echo "✅ llama.cpp ソースビルド完了"
            
        else
            # パッケージインストール成功の場合
            echo "📦 llama.cpp パッケージインストール中..."
            if sudo apt install -y llama.cpp; then
                echo "LLAMA_CLI_PATH=llama-cli" >> $GITHUB_ENV
                echo "✅ llama.cpp パッケージインストール完了"
            else
                echo "❌ パッケージインストール失敗、ソースビルドにフォールバック"
                
                # フォールバック処理
                sudo apt-get install -y build-essential cmake
                git clone --depth 1 https://github.com/ggerganov/llama.cpp.git /tmp/llama.cpp
                cd /tmp/llama.cpp
                make -j$(nproc) LLAMA_NO_ACCELERATE=1
                sudo cp main /usr/local/bin/llama-cli
                sudo cp server /usr/local/bin/llama-server
                echo "LLAMA_CLI_PATH=/usr/local/bin/llama-cli" >> $GITHUB_ENV
                echo "✅ llama.cpp フォールバックビルド完了"
            fi
        fi
        
        # 動作確認
        echo "🧪 llama-cli 動作確認:"
        $LLAMA_CLI_PATH --help | head -5 || echo "バイナリパスを確認中..."
        
        # パスが正しく設定されているか確認
        which llama-cli >/dev/null 2>&1 && echo "✅ llama-cli found in PATH" || echo "ℹ️  llama-cli custom path: $LLAMA_CLI_PATH"
    
    - name: Download LLM model with huggingface-cli
      run: |
        echo "🤖 日本語LLMモデルダウンロード中..."
        mkdir -p models
        
        # 日本語対応の軽量モデルをダウンロード
        huggingface-cli download \
          mmnga/ELYZA-japanese-Llama-2-7b-fast-instruct-gguf \
          ELYZA-japanese-Llama-2-7b-fast-instruct-q4_0.gguf \
          --local-dir models \
          --local-dir-use-symlinks False
        
        # モデルファイル名を統一
        mv models/ELYZA-japanese-Llama-2-7b-fast-instruct-q4_0.gguf models/ggml-model-Q4_K_M.gguf
        
        echo "LLAMA_MODEL_PATH=$(pwd)/models/ggml-model-Q4_K_M.gguf" >> $GITHUB_ENV
        
        # ファイルサイズ確認
        echo "📊 ダウンロード完了:"
        ls -lh models/ggml-model-Q4_K_M.gguf
        echo "✅ LLMモデル準備完了"
    
    - name: Setup and Test SudachiDict-full
      run: |
        echo "🔤 SudachiDict-full 設定・動作確認・テスト実行"
        
        # SudachiPy設定ファイル作成（Full辞書指定）
        mkdir -p ~/.sudachi
        python -c "
        import json
        import os
        from pathlib import Path
        
        # SudachiDict-fullのパスを探す
        try:
            import sudachidict_full
            full_dict_path = Path(sudachidict_full.__file__).parent / 'resources' / 'system.dic'
            print(f'📍 SudachiDict-full パス: {full_dict_path}')
        except ImportError:
            print('⚠️  SudachiDict-fullが見つかりません')
            # フォールバック設定
            full_dict_path = None
        
        # 設定ファイル作成
        config = {
            'systemDict': str(full_dict_path) if full_dict_path and full_dict_path.exists() else None,
            'characterDefinitionFile': 'char.def',
            'inputTextPlugin': [],
            'oovProviderPlugin': [],
            'pathRewritePlugin': [],
            'connectPlugin': []
        }
        
        config_path = Path.home() / '.sudachi' / 'sudachi.json'
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        print(f'📄 設定ファイル作成: {config_path}')
        "
        
        # 動作確認とテスト実行
        python -c "
        import time
        from sudachipy import tokenizer, dictionary
        
        print('🚀 SudachiDict-full 初期化中...')
        start_time = time.time()
        
        try:
            # 設定ファイルを使用して辞書初期化
            tokenizer_obj = dictionary.Dictionary().create()
            init_time = time.time() - start_time
            print(f'⏱️  初期化完了: {init_time:.2f}秒')
            
            # 厚労省・医療関連の専門用語でテスト
            test_cases = [
                '厚生労働省の新しい施策について',
                'テレメディシンによる遠隔診療',
                'レセプト電算処理システム',
                '診療報酬点数表の改定',
                '医療DX推進本部',
                'PHR（Personal Health Record）',
                '地域包括ケアシステム',
                '薬事・食品衛生審議会'
            ]
            
            print('\\n📝 専門用語解析テスト結果:')
            print('=' * 50)
            
            total_tokens = 0
            for i, text in enumerate(test_cases, 1):
                start = time.time()
                tokens = tokenizer_obj.tokenize(text, tokenizer.Tokenizer.SplitMode.A)
                parse_time = time.time() - start
                total_tokens += len(tokens)
                
                print(f'\\n{i}. 「{text}」')
                print(f'   解析時間: {parse_time*1000:.1f}ms | トークン数: {len(tokens)}')
                print('   形態素解析結果:')
                
                for token in tokens:
                    surface = token.surface()
                    reading = token.reading_form() or 'ーー'
                    pos = token.part_of_speech()[0]
                    
                    # 専門用語らしいものをハイライト
                    if pos == '名詞' and len(surface) >= 3:
                        print(f'   🔍 {surface} ({reading}) [{pos}] ← 専門用語候補')
                    else:
                        print(f'     {surface} ({reading}) [{pos}]')
            
            print(f'\\n✅ SudachiDict-full テスト完了')
            print(f'📊 総解析: {len(test_cases)}文 / {total_tokens}トークン')
            print('🎯 専門用語の詳細な分割・読み取りが確認できました')
            
        except Exception as e:
            print(f'❌ SudachiDict-full 初期化エラー: {e}')
            print('🔄 フォールバック: デフォルト辞書を使用します')
            
            # フォールバック処理
            tokenizer_obj = dictionary.Dictionary().create()
            tokens = tokenizer_obj.tokenize('厚生労働省', tokenizer.Tokenizer.SplitMode.A)
            print(f'✅ デフォルト辞書で動作確認完了 ({len(tokens)}トークン)')
        "
        
        echo "📚 インストール済み辞書確認:"
        pip list | grep -i sudachi
    
    - name: Create cache directories
      run: |
        mkdir -p ~/.cache/sudachi
        mkdir -p /tmp
        echo "📁 キャッシュディレクトリ作成完了"
    
    - name: Verify complete environment
      run: |
        echo "🔍 環境確認・動作検証"
        echo "=========================="
        
        echo "🐍 Python環境:"
        python --version
        
        echo "🤖 llama-cli確認:"
        if command -v llama-cli >/dev/null 2>&1; then
            echo "✅ llama-cli found in PATH"
            llama-cli --version 2>/dev/null || llama-cli --help | head -3
        elif [ -f "/usr/local/bin/llama-cli" ]; then
            echo "✅ llama-cli found at /usr/local/bin/llama-cli (source build)"
            /usr/local/bin/llama-cli --version 2>/dev/null || /usr/local/bin/llama-cli --help | head -3
        else
            echo "❌ llama-cli not found"
            exit 1
        fi
        
        echo "🔤 SudachiPy + Full辞書 最終確認:"
        python -c "
        from sudachipy import dictionary
        import os
        tokenizer_obj = dictionary.Dictionary().create()
        # 簡単なテスト
        tokens = tokenizer_obj.tokenize('厚労省', 1)
        print(f'✅ SudachiDict-full 準備完了 (テスト: {len(tokens)}トークン)')
        "
        
        echo "🗄️ Supabase接続確認:"
        echo "SUPABASE_URL: ${SUPABASE_URL:0:30}..."
        
        echo "🤖 LLMモデル確認:"
        echo "Model path: $LLAMA_MODEL_PATH"
        echo "CLI path: $LLAMA_CLI_PATH"
        if [ -f "$LLAMA_MODEL_PATH" ]; then
            file "$LLAMA_MODEL_PATH"
        else
            echo "❌ Model file not found: $LLAMA_MODEL_PATH"
        fi
        
        echo "📦 インストール状況:"
        # パッケージ版の確認
        if dpkg -l | grep -q llama; then
            echo "✅ llama.cpp package installed:"
            dpkg -l | grep llama
        else
            echo "ℹ️  llama.cpp installed via source build"
        fi
        
        # SudachiDict確認
        echo "📚 Sudachi辞書確認:"
        pip list | grep -i sudachi
        
        echo "✅ 環境検証完了 - すべて正常"
    
    - name: Initialize Supabase dictionary (basic words)
      run: |
        echo "🗄️ Supabase 基本辞書初期化"
        
        python3 << 'EOF'
        import os
        from supabase import create_client
        
        print("📡 Supabase接続中...")
        client = create_client(os.environ['SUPABASE_URL'], os.environ['SUPABASE_KEY'])
        
        # 厚労省・医療分野の基本辞書語彙
        basic_words = [
            {'word': '医療', 'reading': 'イリョウ', 'part_of_speech': '名詞', 'source': 'basic'},
            {'word': '厚生労働省', 'reading': 'コウセイロウドウショウ', 'part_of_speech': '名詞', 'source': 'basic'},
            {'word': '健康', 'reading': 'ケンコウ', 'part_of_speech': '名詞', 'source': 'basic'},
            {'word': '診療', 'reading': 'シンリョウ', 'part_of_speech': '名詞', 'source': 'basic'},
            {'word': '薬事', 'reading': 'ヤクジ', 'part_of_speech': '名詞', 'source': 'basic'},
            {'word': '保険', 'reading': 'ホケン', 'part_of_speech': '名詞', 'source': 'basic'},
            {'word': '介護', 'reading': 'カイゴ', 'part_of_speech': '名詞', 'source': 'basic'},
            {'word': '福祉', 'reading': 'フクシ', 'part_of_speech': '名詞', 'source': 'basic'}
        ]
        
        try:
            # 既存チェック
            existing = client.table('dictionary_words').select('word').limit(1).execute()
            if not existing.data:
                client.table('dictionary_words').insert(basic_words).execute()
                print(f"✅ 基本辞書を初期化しました ({len(basic_words)}語)")
            else:
                print("ℹ️  辞書は既に初期化済みです")
            
            # 統計情報
            total_dict_words = client.table('dictionary_words').select('id', count='exact').execute()
            print(f"📊 現在の辞書語彙数: {total_dict_words.count}語")
            
        except Exception as e:
            print(f"⚠️  辞書初期化エラー: {e}")
            import traceback
            traceback.print_exc()
        EOF
        
        echo "✅ Supabase辞書初期化完了"
    
    - name: Run MHLW crawler with SudachiDict-full
      env:
        MAX_WORKERS: ${{ github.event.inputs.max_workers || '3' }}
      run: |
        echo "🚀 厚労省サイト解析クローラー実行開始"
        echo "設定:"
        echo "  - 並列処理数: $MAX_WORKERS"
        echo "  - 辞書: SudachiDict-full (170万語)"
        echo "  - 対象: 厚労省サイト（HTML, PDF, DOCX, PPTX）"
        
        python3 << 'EOF'
        import sys
        import os
        import traceback
        from datetime import datetime
        
        sys.path.append('.')
        
        print(f"🕒 開始時刻: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        try:
            from main_crawler import MhlwCrawler
            
            print("🔧 クローラー初期化中...")
            crawler = MhlwCrawler()
            
            max_workers = int(os.environ.get('MAX_WORKERS', '3'))
            print(f"👥 並列処理数: {max_workers}")
            
            print("📡 クローリング・解析開始...")
            crawler.run(max_workers=max_workers)
            
            print(f"🕒 完了時刻: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print("✅ 厚労省サイト解析完了")
            
        except Exception as e:
            print(f"❌ クローラー実行エラー: {e}")
            traceback.print_exc()
            sys.exit(1)
        EOF
    
    - name: Generate detailed analysis report
      if: always()
      run: |
        echo "📊 解析結果レポート生成中..."
        
        python3 << 'EOF'
        import os
        from supabase import create_client
        from datetime import datetime, timedelta
        
        client = create_client(os.environ['SUPABASE_URL'], os.environ['SUPABASE_KEY'])
        
        # 今日の結果サマリー
        today = datetime.now().date()
        
        print("📈 厚労省サイト専門用語解析結果")
        print("=" * 50)
        print(f"🕒 実行日時: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"🔤 使用辞書: SudachiDict-full (170万語)")
        print("")
        
        # 新語候補数
        try:
            new_words = client.table('new_word_candidates')\
                .select('*')\
                .gte('created_at', today.isoformat())\
                .execute()
            
            # 処理URL数
            processed = client.table('processed_urls')\
                .select('*')\
                .gte('created_at', today.isoformat())\
                .execute()
            
            # 抽出された全単語数
            extracted = client.table('extracted_words')\
                .select('*')\
                .gte('first_found', today.isoformat())\
                .execute()
            
            print(f"📄 処理済URL: {len(processed.data)}件")
            print(f"🔤 抽出単語: {len(extracted.data)}語")
            print(f"🆕 新語候補: {len(new_words.data)}語")
            
            if new_words.data:
                print(f"📊 新語発見率: {len(new_words.data)/max(len(extracted.data),1)*100:.1f}%")
                
                print("\\n🔍 発見された新語候補 TOP 10:")
                print("-" * 40)
                
                # 信頼度でソート
                sorted_words = sorted(new_words.data, 
                                    key=lambda x: x.get('confidence_score', 0), 
                                    reverse=True)
                
                for i, word in enumerate(sorted_words[:10], 1):
                    word_text = word.get('word', 'N/A')
                    reading = word.get('reading', '不明')
                    confidence = word.get('confidence_score', 0)
                    pos = word.get('part_of_speech', '不明')
                    reasoning = word.get('llm_reasoning', '理由不明')[:50]
                    
                    print(f"{i:2d}. {word_text} ({reading})")
                    print(f"    品詞: {pos} | 信頼度: {confidence:.3f}")
                    print(f"    理由: {reasoning}...")
                    print()
            else:
                print("ℹ️  今回の実行では新語候補は見つかりませんでした")
            
            # 辞書統計
            total_dict = client.table('dictionary_words').select('id', count='exact').execute()
            print(f"📚 現在の辞書語彙数: {total_dict.count:,}語")
            
        except Exception as e:
            print(f"⚠️  レポート生成エラー: {e}")
            import traceback
            traceback.print_exc()
        
        print("\\n✅ 解析完了")
        print("🎯 SudachiDict-fullによる高精度専門用語解析が完了しました")
        EOF
    
    - name: Cleanup and optimize storage
      if: always()
      run: |
        echo "🧹 クリーンアップ実行中..."
        
        # 一時ファイル削除
        rm -rf /tmp/*.pdf /tmp/*.docx /tmp/*.pptx /tmp/*.txt
        
        # pip キャッシュクリア（容量節約）
        pip cache purge
        
        # modelsディレクトリは保持（次回実行時の再ダウンロード回避）
        echo "💾 LLMモデルファイルは保持（再利用のため）"
        
        # ディスク使用量確認
        echo "💽 ディスク使用量:"
        df -h | head -2
        
        echo "✅ クリーンアップ完了"
    
    - name: Upload comprehensive logs
      if: failure()
      uses: actions/upload-artifact@v4
      with:
        name: mhlw-crawler-logs-${{ github.run_id }}
        path: |
          *.log
          /tmp/crawler_*.txt
          /tmp/sudachi_*.log
          /var/log/syslog
        retention-days: 14
        if-no-files-found: ignore
