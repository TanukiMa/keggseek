# config.ini

[General]
START_URL = https://www.kegg.jp/medicus-bin/search_drug
TARGET_DOMAIN = www.kegg.jp
REQUEST_TIMEOUT = 30

[Seeds]
# SITEMAP_URLが存在しないため、この行をコメントアウトする
# SITEMAP_URL = https://www.kegg.jp/medicus-bin/search_drug
INDEX_PAGES = 
    https://www.kegg.jp/medicus-bin/search_drug

[Discoverer]
# 0で上限なし
MAX_URLS_TO_DISCOVER = 0
# URL発見処理の並列スレッド数
MAX_DISCOVER_WORKERS = 1
DB_WRITE_BATCH_SIZE = 100
# 収集するリンクの階層の深さ (1 = INDEX_PAGESの直下のみ)
CRAWL_DEPTH = 2

[Processor]
MAX_WORKERS = 1
PROCESS_BATCH_SIZE = 48

[RateLimit]
# 1分あたりの目標最大アクセス数
# ワークフローで並列実行するインスタンス数を考慮して設定してください。
# (例: 3インスタンスで合計30アクセスにしたい場合、ここを10に設定)
TARGET_ACCESSES_PER_MINUTE = 60
# discoverプロセスが1分あたりにアクセスする最大URL数
DISCOVER_ACCESSES_PER_MINUTE = 60
# processプロセスが1分あたりにアクセスする最大URL数
PROCESS_ACCESSES_PER_MINUTE = 30
REQUEST_DELAY_SECONDS = 2

[Debug]
# process_queue.pyで詳細な解析ログを出力する場合はtrueにする
PROCESSOR_DEBUG = false
